{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from pypinyin import pinyin, lazy_pinyin, Style\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "from nltk.translate import bleu\n",
    "from copy import deepcopy\n",
    "\n",
    "from utils import *\n",
    "# Define a device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(in_path,out_path,with_all_couplets=True):\n",
    "    batch_size = 1 # ------------\n",
    "    nb_couplets = 1024\n",
    "    \n",
    "    print(\"### data preparing ### \")\n",
    "    print(\"Batch size is: \",batch_size)\n",
    "    print(\"Use all couplets to train: \",with_all_couplets)\n",
    "    if (with_all_couplets==False):\n",
    "        print(\"\\tTherefore nb_couplets to train is: \",nb_couplets)\n",
    "\n",
    "    print(\"### data loading ### \")\n",
    "    vocab_path = \"./vocab_total_ori.txt\"\n",
    "    data_in, data_out, max_length = load_data(in_path,out_path,nb_couplets,with_all_couplets)\n",
    "    vocab = load_vocab(vocab_path)\n",
    "    vocab_size = len(vocab)\n",
    "    print(\"Vocab length is \", vocab_size)\n",
    "    return data_in,data_out,vocab,max_length\n",
    "\n",
    "def create_dicts(data_in,data_out,vocab,max_length):\n",
    "\n",
    "    # create char2int and int2char_dict\n",
    "    char2int_dict, int2char_dict = create_char2int_and_int2char_dict(vocab)\n",
    "    \n",
    "    char2tone_dict = create_char2tone_dict(vocab)\n",
    "    \n",
    "    int2tone_dict = dict()\n",
    "    for i in range(len(vocab)):\n",
    "        t = char2tone_dict.get(vocab[i])\n",
    "        int2tone_dict[i] = t\n",
    "\n",
    "    return char2int_dict, int2char_dict, char2tone_dict, int2tone_dict\n",
    "        \n",
    "        \n",
    "def create_tone_mask(vocab, char2tone_dict):\n",
    "    tone_onlyP_2 = np.ones(len(vocab))\n",
    "    tone_onlyZ_2 = np.ones(len(vocab))\n",
    "    for i in range(len(vocab)):\n",
    "        # i  <=> char_id   \n",
    "        tone = char2tone_dict.get(vocab[i])\n",
    "        if (tone.isalpha()):\n",
    "            if (len(tone) != 2):\n",
    "                if(tone == 'P'):\n",
    "                    tone_onlyP_2[i] = 92233720368547758\n",
    "                else:\n",
    "                    tone_onlyZ_2[i] = 92233720368547758\n",
    "    return tone_onlyP_2, tone_onlyZ_2\n",
    "\n",
    "    \n",
    "# tokenize: couplet to int \n",
    "def tokenize_(data, char2int_dict, max_length):  \n",
    "    v=[]\n",
    "    for i in range(0, len(data)):\n",
    "        l = []\n",
    "        for j in range (0, len(data[i])):\n",
    "            if ( char2int_dict.get(data[i][j])  is None ):\n",
    "                l.append(   char2int_dict.get('UNK')  )\n",
    "            else:\n",
    "                l.append(   char2int_dict.get(data[i][j])  )\n",
    "        if (len(data[i]) < max_length):   # padding 0(pad) at the end\n",
    "            l = (l + [0] * max_length)[:max_length]\n",
    "        v.append(l)\n",
    "    return v\n",
    "\n",
    "\n",
    "def tokenize_dec_in_(data, char2int_dict, max_length): \n",
    "    v=[]\n",
    "    for i in range(0, len(data)):\n",
    "        l = [char2int_dict.get('sos')]\n",
    "\n",
    "        for j in range (0, len(data[i])):\n",
    "            if ( char2int_dict.get(data[i][j])  is None ):\n",
    "                l.append(   char2int_dict.get('UNK')  )\n",
    "            else:\n",
    "                l.append(   char2int_dict.get(data[i][j])  )\n",
    "        if (len(data[i]) < max_length):   # padding 0(pad) at the end\n",
    "            l = (l + [0] * max_length)[:max_length]\n",
    "        v.append(l)\n",
    "    return v\n",
    "\n",
    "\n",
    "def tokenize_dec_out_(data, char2int_dict, max_length): \n",
    "    v=[]\n",
    "    for i in range(0, len(data)):\n",
    "        l = []\n",
    "        for j in range (0, len(data[i])):\n",
    "            if ( char2int_dict.get(data[i][j])  is None ):\n",
    "                l.append(   char2int_dict.get('UNK')  )\n",
    "            else:\n",
    "                l.append(   char2int_dict.get(data[i][j])  )\n",
    "\n",
    "        l.append(char2int_dict.get('eos'))\n",
    "        if (len(data[i]) < max_length):   # padding 0(pad) at the end\n",
    "            l = (l + [0] * max_length)[:max_length]\n",
    "        v.append(l)\n",
    "    return v\n",
    "\n",
    "def tokenization(data_in,data_out,char2int_dict,max_length):\n",
    "    # Line One from character to int\n",
    "    Enc_in =  tokenize_(data_in,char2int_dict,max_length)\n",
    "    # Line two from character to int, with SOS and EOS\n",
    "    token_out =tokenize_(data_out,char2int_dict,max_length)\n",
    "    Dec_in = tokenize_dec_in_(data_out,char2int_dict,max_length)\n",
    "    Dec_out = tokenize_dec_out_(data_out,char2int_dict,max_length)  \n",
    "    \n",
    "    return  Enc_in,Dec_in,Dec_out\n",
    "\n",
    "def prepare_batches(Enc_in,Dec_out,Dec_in,batch_size=1):\n",
    "    in_ = []\n",
    "    for i in range(0,int(len(Enc_in)/batch_size)):\n",
    "        in_.append( torch.Tensor(Enc_in[batch_size*i:batch_size*(i+1)]).to(torch.int64) )\n",
    "    out_ = []\n",
    "    for i in range(0,int(len(Dec_out)/batch_size)):\n",
    "        out_.append( torch.Tensor(Dec_out[batch_size*i:batch_size*(i+1)]).to(torch.int64) )\n",
    "    dec_in_ =[]\n",
    "    for i in range(0,int(len(Dec_in)/batch_size)):\n",
    "        dec_in_.append( torch.Tensor(Dec_in[batch_size*i:batch_size*(i+1)]).to(torch.int64) )\n",
    "    batch_in_out_pairs =[]   # may ignore some last couplets\n",
    "    for i in range(0, len(in_)):\n",
    "        batch_in_out_pairs.append((in_[i],dec_in_[i], out_[i]))\n",
    "    print(\"Number of couplet batches :\",len(batch_in_out_pairs))\n",
    "    \n",
    "    return batch_in_out_pairs\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self,indices,acc,hid,attn):\n",
    "        self.indices = indices\n",
    "        self.acc = acc\n",
    "        self.hid = hid\n",
    "        self.attn = attn\n",
    "\n",
    "        \n",
    "    def add_vi(self,val_,idx_,hid,attn):\n",
    "        self.indices.append(idx_)\n",
    "        self.acc = val_\n",
    "        self.hid.append(hid)\n",
    "        self.attn.append(attn)\n",
    "    \n",
    "    def printf(self):\n",
    "        print(\"=> In Node:\")\n",
    "        print(\"=> Acc is: \",float(self.acc))\n",
    "        print(\"=> Indices are:\", [i for i in self.indices])\n",
    "\n",
    "def detokenize_All(couplets, int2char_dict):\n",
    "    o = ''\n",
    "    for i in range(0, len(couplets)):\n",
    "        for j in range(len(couplets[i])):\n",
    "            if (couplets[i][j] >= 3):    # ignore pad,sos,eos\n",
    "                o = o + int2char_dict.get(couplets[i][j].item()) \n",
    "        #o = o +\"\\n\"\n",
    "    return o\n",
    "\n",
    "def detokenize_int(one_couplet, int2char_dict):\n",
    "    o = ''\n",
    "    for i in range(0, len(one_couplet)):\n",
    "        if(int2char_dict.get(one_couplet[i]) is not None):\n",
    "            o = o + int2char_dict.get(one_couplet[i])   # one_couplet should be like [24,576,134]\n",
    "        else:\n",
    "            print(\"what\")\n",
    "    return o\n",
    "\n",
    "\n",
    "# create a dictionary of repeted words\n",
    "def dict_repet_idx(one_tensor,length):\n",
    "    records_array = np.array(one_tensor)[:length]\n",
    "    vals, inverse, count = np.unique(records_array, return_inverse=True,return_counts=True)\n",
    "    idx_vals_repeated = np.where(count > 1)[0]\n",
    "    vals_repeated = vals[idx_vals_repeated]\n",
    "\n",
    "    rows, cols = np.where(inverse == idx_vals_repeated[:, np.newaxis])\n",
    "    _, inverse_rows = np.unique(rows, return_index=True)\n",
    "    res = np.split(cols, inverse_rows[1:])\n",
    "    \n",
    "    d = dict()\n",
    "    for i in range(len(res)):\n",
    "        for l in range(1,len(res[i])):\n",
    "            val = res[i][0]\n",
    "            d[ res[i][l] ]  = val\n",
    "    \n",
    "    return d\n",
    "\n",
    "\n",
    "# If input couplet consists of some same characters\n",
    "# Then this method forces the output couplet to have same character at corresponding position\n",
    "def detokenize_int_repet(input_tensor, one_couplet, int2char_dict):\n",
    "    o = ''\n",
    "    longueur = np.where(np.array(input_tensor[0]) == 0)[0][0]\n",
    "    d = dict_repet_idx(input_tensor[0],longueur)\n",
    "    #print(\"Input length is \",longueur)\n",
    "    \n",
    "    for i in range(0, len(one_couplet)):\n",
    "        idx = d.get(i)\n",
    "        if ( idx is not None ):\n",
    "            # use the first appreared word\n",
    "            o = o + int2char_dict.get(one_couplet[idx])\n",
    "        else:\n",
    "            o = o + int2char_dict.get(one_couplet[i])\n",
    "    return o\n",
    "\n",
    "\n",
    "# Evaluate one couplet\n",
    "def evaluate(char2tone_dict,encoder, decoder,input_tensor,forced_tone=True,forced_word=True, beam_width=1, max_length=33):\n",
    "    \n",
    "    batch_size = input_tensor.size(0)\n",
    "    target_length = input_tensor.size(1)\n",
    "    \n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    longueur = [np.where(np.array(input_tensor[0]) == 0)[0][0]]\n",
    "    with torch.no_grad():\n",
    "        encoder_hidden = torch.zeros(2, batch_size, hidden_size)\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor, encoder_hidden,longueur)\n",
    "        decoder_input = torch.tensor([1])\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input.to(device), decoder_hidden.to(device), encoder_outputs.to(device))\n",
    "        \n",
    "        if(forced_tone):\n",
    "            tone = int2tone_dict.get(int(input_tensor[0][0]))\n",
    "            if( tone is not None and tone.isalpha() and len(tone) != 2 ):\n",
    "\n",
    "                if (tone == 'P'):\n",
    "                    decoder_output = decoder_output*torch.Tensor(tone_onlyP_2)\n",
    "                else:\n",
    "                    decoder_output = decoder_output*torch.Tensor(tone_onlyZ_2)        \n",
    "        \n",
    "        \n",
    "        topv, topi = decoder_output.squeeze(1).topk(beam_width)\n",
    "        \n",
    "        decoder_input = topi.detach().t() # t() for convenience dec_in shape\n",
    "        \n",
    "        list_nodes = []\n",
    "        init_node = Node( [], 0,[],[])  # indices,acc,hid,attn\n",
    "        for l in range(0,beam_width):\n",
    "            node = deepcopy(init_node)\n",
    "            node.add_vi(topv[0][l],int(topi[0][l]),decoder_hidden,decoder_attention)\n",
    "            list_nodes.append(node)  \n",
    "\n",
    "        for j in range (1,longueur[0]):\n",
    "            temp_val = []\n",
    "            temp_idx = []\n",
    "            temp_hid = []\n",
    "            temp_attn = []\n",
    "            for b in range(beam_width):\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(torch.tensor([ list_nodes[b].indices[-1] ]), list_nodes[b].hid[-1], encoder_outputs)\n",
    "                \n",
    "                if(forced_tone):\n",
    "                    tone = int2tone_dict.get(int(input_tensor[0][j]))\n",
    "                    if( tone is not None and tone.isalpha() and len(tone) != 2 ):\n",
    "\n",
    "                        if (tone == 'P'):\n",
    "                            decoder_output = decoder_output*torch.Tensor(tone_onlyP_2)  \n",
    "                        else:\n",
    "                            decoder_output = decoder_output*torch.Tensor(tone_onlyZ_2) \n",
    "                            \n",
    "                \n",
    "                topv, topi = decoder_output.squeeze(1).topk(beam_width)\n",
    "                \n",
    "                temp_val.append(topv) \n",
    "                temp_idx.append(topi)\n",
    "                temp_hid.append(decoder_hidden)\n",
    "                temp_attn.append(decoder_attention)\n",
    "                \n",
    "            for bb in range(beam_width):\n",
    "                temp_val[bb] += list_nodes[bb].acc \n",
    "            \n",
    "            concat = temp_val[0]\n",
    "            concat_idx = temp_idx[0]\n",
    "            concat_hid = []\n",
    "            concat_hid.append(temp_hid[0])\n",
    "            concat_attn = []\n",
    "            concat_attn.append(temp_attn[0])\n",
    "            for bbb in range(1,beam_width):\n",
    "                concat = torch.cat((concat,temp_val[bbb]),dim=1)\n",
    "                concat_idx = torch.cat((concat_idx,temp_idx[bbb]),dim=1)\n",
    "                concat_hid.append(temp_hid[bbb])\n",
    "                concat_attn.append(temp_attn[bbb])\n",
    "            concat = concat.squeeze()\n",
    "            concat_idx = concat_idx.squeeze()\n",
    "            if(beam_width == 1):\n",
    "                concat = concat.unsqueeze(0)\n",
    "                concat_idx = concat_idx.unsqueeze(0)\n",
    "\n",
    "            tv, ti = concat.topk(beam_width)\n",
    "\n",
    "            new_list_nodes = []\n",
    "            for bbbb in range(beam_width):\n",
    "                quel_node =  int(int(ti[bbbb]) / beam_width)\n",
    "                corr_nodes = list_nodes[quel_node] \n",
    "\n",
    "                new = deepcopy(corr_nodes)\n",
    "                new.add_vi(concat[ti[bbbb]], int(concat_idx[ti[bbbb]]),concat_hid[quel_node],concat_attn[quel_node] )\n",
    "\n",
    "                new_list_nodes.append(deepcopy(new))\n",
    "\n",
    "            new_dec_in = []\n",
    "            for e in range(len(new_list_nodes)):\n",
    "                nn = new_list_nodes[e]\n",
    "                new_dec_in.append(nn.indices[-1])\n",
    "            new_dec_in = torch.tensor(new_dec_in).unsqueeze(1)\n",
    "            \n",
    "            list_nodes = deepcopy(new_list_nodes)\n",
    "            decoder_input = new_dec_in\n",
    "\n",
    "        decoded_words=[]\n",
    "        for kk in range(len(list_nodes)):\n",
    "            nnn = list_nodes[kk]\n",
    "            d = nnn.indices\n",
    "            \n",
    "            if (forced_word):\n",
    "                decoded_words.append( detokenize_int_repet(input_tensor, d, int2char_dict) )\n",
    "            else:\n",
    "                decoded_words.append( detokenize_int(d, int2char_dict) )\n",
    "    return decoded_words, list_nodes\n",
    "            \n",
    "    \n",
    "# Evaluate randomly n couplets\n",
    "def evaluateRandomly(char2tone_dict,encoder, decoder,forced_tone=True,forced_word=False,beam_width=1, n=1):\n",
    "\n",
    "    for i in range(n):\n",
    "        print(\"Index is \",i)\n",
    "        i = np.random.randint(len(Enc_in))\n",
    "        pair = torch.Tensor([Enc_in[i] ]).to(torch.int64)\n",
    "        d_out =torch.Tensor([Dec_in[i] ]).to(torch.int64)\n",
    "        output_words, list_nodes = evaluate(char2tone_dict,encoder, decoder, pair,forced_tone,forced_word,beam_width)\n",
    "        output_words_line = '\\n'.join(output_words)\n",
    "        \n",
    "        print(\"Coulet Input: \")\n",
    "        inn = detokenize_All(pair, int2char_dict)\n",
    "        print(inn)\n",
    "        print('Model Answer: ')\n",
    "        print(output_words_line)\n",
    "        print(\"Desired Answer: \")\n",
    "        outt = detokenize_All(d_out, int2char_dict)\n",
    "        print(outt)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        \n",
    "        # If you want to plot the attention\n",
    "        # Decomment the following code\n",
    "        \"\"\"\"\"\n",
    "        attn = []\n",
    "        for w in range(len(list_nodes)):\n",
    "            #print(\"w is \",w)\n",
    "            a = list_nodes[w].attn\n",
    "            #print(\"len attn\",len(a))\n",
    "            attn_tmp = torch.tensor(())\n",
    "            for m in range(len(a)):\n",
    "                b = torch.tensor(a[m][0])\n",
    "                #plt.subplots(figsize=(5, 9))\n",
    "                #plt.imshow(b,cmap='hot')\n",
    "                #plt.show()\n",
    "                attn_tmp = torch.cat((attn_tmp, b),0) \n",
    "                \n",
    "            #showAttention(pair, output_words[k], list_nodes[k].attn)\n",
    "            #print(\"tmp shape\",attn_tmp.shape)  # for j in longueur or max_length\n",
    "            \n",
    "            plt.subplots(figsize=(3, 2))\n",
    "            #plt.imshow(attn_tmp[:8,:8],cmap='hot')\n",
    "            plt.imshow(attn_tmp,cmap='hot')\n",
    "\n",
    "            plt.colorbar()\n",
    "            plt.show()\n",
    "            attn.append(attn_tmp)\n",
    "        \"\"\"\"\"\n",
    "    \n",
    "# Compute bleu score\n",
    "def compute_bleu(char2tone_dict,encoder, decoder,forced_tone=False,forced_word=False,beam_width=1, n=1):\n",
    "    total_bleu = 0\n",
    "    count=0\n",
    "\n",
    "    for i in range(n):\n",
    "        pair = torch.Tensor([Enc_in[i] ]).to(torch.int64)\n",
    "        d_out =torch.Tensor([Dec_in[i] ]).to(torch.int64)\n",
    "        \n",
    "        output_words, list_nodes = evaluate(char2tone_dict,encoder, decoder, pair,forced_tone,forced_word,beam_width)\n",
    "        output_words_line = '\\n'.join(output_words)\n",
    "        inn = detokenize_All(pair, int2char_dict)\n",
    "        outt = detokenize_All(d_out, int2char_dict)\n",
    "       \n",
    "        for k in range(len(output_words)):\n",
    "            smoothie = SmoothingFunction().method4\n",
    "            if( len(outt) == 1 and outt==output_words[k]):  # otherwise division 0\n",
    "                total_bleu += 1.0\n",
    "                count+=1\n",
    "            else:\n",
    "                b = bleu([outt], output_words[k], smoothing_function=smoothie)\n",
    "                total_bleu += b\n",
    "                if(b >= 0.2):\n",
    "                    count+=1\n",
    "                    \n",
    "    print(\"## FIN ##\")\n",
    "    print(\"BLEU :\",total_bleu/ (n*beam_width)  )\n",
    "    print(\"#count >0.2 :\",count/beam_width)        \n",
    "        \n",
    "# need data_in, data_out, Enc_in Dec_out\n",
    "def for_humain_eval(i,n,pt,char2tone_dict,indices,om,forced_tone=True,forced_word=False,beam_width=1):\n",
    "    encoder = torch.load(\"./models/II_enc_epoch_\"+pt+\".pt\",map_location='cpu')\n",
    "    attn_decoder = torch.load(\"./models/II_dec_epoch_\"+pt+\".pt\",map_location='cpu')\n",
    "    encoder.eval()\n",
    "    attn_decoder.eval()\n",
    "    print(\"encoder.hidden_size:\",encoder.hidden_size)\n",
    "    print(\"attn_decoder.hidden_size:\",attn_decoder.hidden_size)\n",
    "\n",
    "    f = open(\"./random_\"+str(i)+\"_\"+pt+\"_\"+str(forced_tone)+\"_\"+str(forced_word)+\"_\"+str(beam_width)+\".txt\",\"w\")\n",
    "    f_oomm = open(\"./random_oomm_\"+str(i)+\"_\"+pt+\"_\"+str(forced_tone)+\"_\"+str(forced_word)+\"_\"+str(beam_width)+\".txt\",\"w\")\n",
    "    f_a = open(\"./random_notes_\"+str(i)+\"_\"+pt+\"_\"+str(forced_tone)+\"_\"+str(forced_word)+\"_\"+str(beam_width)+\".txt\",\"w\")\n",
    "    \n",
    "    \n",
    "    f_a.write(\"### oo => 0, mm => 1 ###\")\n",
    "    f_a.write(\"\\n\")\n",
    "    \n",
    "    for idx in range(n):\n",
    "        \n",
    "        f_a.write(\"-Question-\"+str(idx+1)+\"\\n\")\n",
    "        f_a.write(\"Indices:\"+str(indices[idx])+\"\\n\")\n",
    "        f_a.write(\"Truth:\"+str(om[idx])+\"\\n\")\n",
    "        f_a.write(\"\\n\")\n",
    "    \n",
    "        # generate model answer\n",
    "        i = indices[idx]\n",
    "        pair = torch.Tensor(Enc_in[i]).to(torch.int64).unsqueeze(0)\n",
    "        d_out = torch.Tensor(Dec_in[i]).to(torch.int64).unsqueeze(0)\n",
    "        output_words, _ = evaluate(char2tone_dict,encoder, attn_decoder, pair,forced_tone,forced_word,beam_width)\n",
    "        \n",
    "        # without oomm \n",
    "        f.write(\"-Question-\"+str(idx+1)+\"\\n\")\n",
    "        f.write(\"Indices:\"+str(i)+\"\\n\")\n",
    "        f.write(data_in[i]+\" ii\\n\")\n",
    "        if(om[idx] == 0):\n",
    "            f.write(data_out[i]+\"\\n\")\n",
    "            f.write(output_words[0]+\"\\n\")\n",
    "        else:\n",
    "            f.write(output_words[0]+\"\\n\")\n",
    "            f.write(data_out[i]+\"\\n\")\n",
    "        f.write('\\n')\n",
    "        \n",
    "        # with oomm    \n",
    "        f_oomm.write(\"-Question-\"+str(idx+1)+\"\\n\")\n",
    "        f_oomm.write(\"Indices:\"+str(i)+\"\\n\")\n",
    "        f_oomm.write(data_in[i]+\" ii\\n\")   \n",
    "        if(om[idx] == 0): \n",
    "            f_oomm.write(data_out[i]+\" oo\\n\")\n",
    "            f_oomm.write(output_words[0]+\" mm\\n\")\n",
    "        else:\n",
    "            f_oomm.write(output_words[0]+\" mm\\n\")\n",
    "            f_oomm.write(data_out[i]+\" oo\\n\")            \n",
    "        f_oomm.write('\\n')\n",
    "        \n",
    "    f_a.close\n",
    "    f.close\n",
    "    f_oomm.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Evaluation\n",
    "Prepare couplets to be evaluated latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = \"./test_in_remov.txt\"\n",
    "out_path = \"./test_out_remov.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load couplets data and create necessary tools for the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### data preparing ### \n",
      "Batch size is:  1\n",
      "Use all couplets to train:  True\n",
      "### data loading ### \n",
      "min line length is  1\n",
      "max line length is  32\n",
      "Loaded input couplets length is  3931\n",
      "Loaded output couplets length is  3931\n",
      "Vocab length is  9131\n",
      "Number of couplet batches : 3931\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "data_in,data_out,vocab,max_length = prepare_data(in_path,out_path,with_all_couplets=True)\n",
    "char2int_dict, int2char_dict, char2tone_dict, int2tone_dict = create_dicts(data_in,data_out,vocab,max_length)\n",
    "tone_onlyP_2, tone_onlyZ_2 = create_tone_mask(vocab, char2tone_dict)\n",
    "Enc_in,Dec_in,Dec_out = tokenization(data_in,data_out,char2int_dict,max_length)\n",
    "batch_in_out_pairs_eval = prepare_batches(Enc_in,Dec_out,Dec_in,batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Encoder and Decoder from `models` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = torch.load(\"./models/II_enc_epoch_203.pt\",map_location='cpu')\n",
    "attn_decoder = torch.load(\"./models/II_dec_epoch_203.pt\",map_location='cpu')\n",
    "encoder.eval()\n",
    "attn_decoder.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate randomly n couplets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index is  0\n",
      "Coulet Input: \n",
      "牛耕九野\n",
      "Model Answer: \n",
      "虎跃千山\n",
      "Desired Answer: \n",
      "虎啸八方\n",
      "\n",
      "\n",
      "Index is  1\n",
      "Coulet Input: \n",
      "中坚才女立宏志\n",
      "Model Answer: \n",
      "上下光前读异书\n",
      "Desired Answer: \n",
      "馥郁桂花开仲秋\n",
      "\n",
      "\n",
      "Index is  2\n",
      "Coulet Input: \n",
      "旧宅翻成新宅\n",
      "Model Answer: \n",
      "新居坐到旧居\n",
      "Desired Answer: \n",
      "今年胜过去年\n",
      "\n",
      "\n",
      "Index is  3\n",
      "Coulet Input: \n",
      "白云亭阁送归去\n",
      "Model Answer: \n",
      "绿水春光迎晚来\n",
      "Desired Answer: \n",
      "绿色河山迎再来\n",
      "\n",
      "\n",
      "Index is  4\n",
      "Coulet Input: \n",
      "一棹天边影\n",
      "Model Answer: \n",
      "几行水上情\n",
      "Desired Answer: \n",
      "千峰云外山\n",
      "\n",
      "\n",
      "Index is  5\n",
      "Coulet Input: \n",
      "千年事业方寸内\n",
      "Model Answer: \n",
      "万里江山万卷中\n",
      "Desired Answer: \n",
      "万里乾坤掌握中\n",
      "\n",
      "\n",
      "Index is  6\n",
      "Coulet Input: \n",
      "溪头几串童年梦\n",
      "Model Answer: \n",
      "柳下一行稚子情\n",
      "Desired Answer: \n",
      "心底一支岁月歌\n",
      "\n",
      "\n",
      "Index is  7\n",
      "Coulet Input: \n",
      "空庭草色和烟暖\n",
      "Model Answer: \n",
      "野渡花香逐浪高\n",
      "Desired Answer: \n",
      "午夜书声带月寒\n",
      "\n",
      "\n",
      "Index is  8\n",
      "Coulet Input: \n",
      "星辉南极岁之始\n",
      "Model Answer: \n",
      "月照中华秋所归\n",
      "Desired Answer: \n",
      "雨足西江云自闲\n",
      "\n",
      "\n",
      "Index is  9\n",
      "Coulet Input: \n",
      "牛排无竹不能荡\n",
      "Model Answer: \n",
      "马上有声就可行\n",
      "Desired Answer: \n",
      "鸡柳没油也可尝\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(char2tone_dict,encoder, attn_decoder,forced_tone=True,forced_word=True,beam_width=1,n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute bleu score for models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## FIN ##\n",
      "BLEU : 0.13963461478725833\n",
      "#count >0.2 : 1178.0\n"
     ]
    }
   ],
   "source": [
    "# 203\n",
    "compute_bleu(char2tone_dict,encoder, attn_decoder,forced_tone=True,forced_word=True,beam_width=1,n=len(batch_in_out_pairs_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## FIN ##\n",
      "BLEU : 0.1380228152769069\n",
      "#count >0.2 : 1151.3333333333333\n"
     ]
    }
   ],
   "source": [
    "# 203\n",
    "compute_bleu(char2tone_dict,encoder, attn_decoder,forced_tone=True,forced_word=True,beam_width=3,n=len(batch_in_out_pairs_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## FIN ##\n",
      "BLEU : 0.13732333521721898\n",
      "#count >0.2 : 1146.6\n"
     ]
    }
   ],
   "source": [
    "# 203\n",
    "compute_bleu(char2tone_dict,encoder, attn_decoder,forced_tone=True,forced_word=True,beam_width=5,n=len(batch_in_out_pairs_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
